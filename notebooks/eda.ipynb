{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ed531f",
   "metadata": {},
   "source": [
    "### In this notebook we explore the data lightly and create some preliminary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc65a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "import collections\n",
    "import os\n",
    "\n",
    "processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "unprocessed_folder_path = os.path.join(\"..\", \"data\", \"unprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c137f9",
   "metadata": {},
   "source": [
    "## Plot data density\n",
    "\n",
    "### NDSI and NDVI data density given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDSI = pd.read_csv(os.path.join(processed_folder_path, \"NDSI.csv\"), index_col=0, parse_dates=[\"date\"],\n",
    "                     dtype={\"Subsubwatershed\": str})\n",
    "df_NDVI = pd.read_csv(os.path.join(processed_folder_path, \"NDVI.csv\"), index_col=0, parse_dates=[\"date\"],\n",
    "                     dtype={\"Subsubwatershed\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_density(dfs, labels):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for df, label in zip(dfs, labels):\n",
    "        plt.plot(df.groupby(df[\"date\"].dt.year).size(), label=label)\n",
    "    \n",
    "    plt.title(\"Frequency of years in data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for df, label in zip(dfs, labels):\n",
    "        plt.plot(df.groupby(df[\"date\"].dt.month).size(), label=label)\n",
    "\n",
    "    plt.xticks(range(12), range(1, 13))\n",
    "    plt.title(\"Frequency of months in data\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e31b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_density([df_NDSI, df_NDVI], [\"NDSI\", \"NDVI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02b8df",
   "metadata": {},
   "source": [
    "## River Flow Data\n",
    "### Data Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DGA = pd.read_csv(os.path.join(processed_folder_path, \"DGA.csv\"), index_col=0, parse_dates=[\"date\"])\n",
    "df_DGA = df_DGA.loc[df_DGA[\"date\"].dt.year >= 1965]\n",
    "\n",
    "plot_data_density([df_DGA], [\"DGA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1e6b8",
   "metadata": {},
   "source": [
    "### Monthly Flow Data\n",
    "\n",
    "We convert the data from a daily scale to a monthly scale by calculating the mean and the median per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22757983",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_flow_data_mean = df_DGA.groupby(pd.PeriodIndex(df_DGA['date'], freq=\"M\"))[['river_flow', 'river_height']].mean()\n",
    "monthly_flow_data_median = df_DGA.groupby(pd.PeriodIndex(df_DGA['date'], freq=\"M\"))['river_flow'].median()\n",
    "\n",
    "flow_mean_df = monthly_flow_data_mean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896018ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = [\"03400\", \"03401\", \"03402\", \n",
    "                \"03403\", \"03404\", \"03410\", \n",
    "                \"03411\", \"03412\", \"03413\", \n",
    "                \"03414\", \"03420\", \"03421\"]\n",
    "\n",
    "keep_rows_ndsi = df_NDSI[df_NDSI.Subsubwatershed.isin(station_list)].index\n",
    "keep_rows_ndvi = df_NDVI[df_NDVI.Subsubwatershed.isin(station_list)].index\n",
    "\n",
    "df_NDSI = df_NDSI[df_NDSI.index.isin(keep_rows_ndsi)]\n",
    "df_NDVI = df_NDVI[df_NDVI.index.isin(keep_rows_ndvi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_NDSI.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e5948",
   "metadata": {},
   "source": [
    "### Below we merge the NDSI and NDVI dataframes into the monthly_flow_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feed702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lags(df, values, n_lags):\n",
    "    \"\"\"\n",
    "    generate_lags\n",
    "    Generates a dataframe with columns denoting lagged value up to n_lags\n",
    "    Args:\n",
    "        df: dataframe to lag\n",
    "        value: values to lag\n",
    "        n_lags: amount of rows to lag\n",
    "    \"\"\"\n",
    "    df_n = df.copy()\n",
    "\n",
    "    for value in values:\n",
    "        for n in range(1, n_lags + 1):\n",
    "            df_n[f\"{value}_{n}\"] = df_n[f\"{value}\"].shift(n)\n",
    "\n",
    "    df_n = df_n.iloc[n_lags:]\n",
    "\n",
    "    return df_n\n",
    "\n",
    "def generate_cyclical_features(df, col_name, period, start_num=0):\n",
    "\n",
    "    kwargs = {\n",
    "        f\"sin_{col_name}\":\n",
    "            lambda x: np.sin(2 * np.pi * (df[col_name] - start_num) / period),\n",
    "        f\"cos_{col_name}\":\n",
    "            lambda x: np.cos(2 * np.pi * (df[col_name] - start_num) / period)\n",
    "    }\n",
    "\n",
    "    return df.assign(**kwargs).drop(columns=[col_name])\n",
    "\n",
    "\n",
    "def gather_ndsi_ndvi_data(watersheds=None):\n",
    "    \"\"\"\n",
    "    This function returns the full processed data using various arguments\n",
    "    as a pd.DataFrame\n",
    "    Args:\n",
    "        watersheds: list of strings denoting what watersheds to use from data\n",
    "        lag: amount of time lag to be used as features\n",
    "    \"\"\"\n",
    "    processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "    if watersheds == None:\n",
    "\n",
    "        watersheds = [\"03400\", \"03401\", \"03402\",\n",
    "                      \"03403\", \"03404\", \"03410\",\n",
    "                      \"03411\", \"03412\", \"03413\",\n",
    "                      \"03414\", \"03420\", \"03421\"]\n",
    "    \n",
    "    df_NDSI = pd.read_csv(os.path.join(processed_folder_path, \"NDSI.csv\"),\n",
    "                          index_col=0, parse_dates=[\"date\"],\n",
    "                          dtype={\"Subsubwatershed\": str})\n",
    "    df_NDVI = pd.read_csv(os.path.join(processed_folder_path, \"NDVI.csv\"),\n",
    "                          index_col=0, parse_dates=[\"date\"],\n",
    "                          dtype={\"Subsubwatershed\": str})\n",
    "    \n",
    "    # Only preserve rows inside subsubwatershed list\n",
    "    keep_rows_ndsi = df_NDSI[df_NDSI.Subsubwatershed.isin(watersheds)].index\n",
    "    keep_rows_ndvi = df_NDVI[df_NDVI.Subsubwatershed.isin(watersheds)].index\n",
    "\n",
    "    df_NDSI = df_NDSI[df_NDSI.index.isin(keep_rows_ndsi)]\n",
    "    df_NDVI = df_NDVI[df_NDVI.index.isin(keep_rows_ndvi)]\n",
    "    \n",
    "    return df_NDSI, df_NDVI\n",
    "\n",
    "\n",
    "def aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, column):\n",
    "    \"\"\"\n",
    "    This function will correctly aggregate area data given the column\n",
    "    Args:\n",
    "        df_NDSI: dataframe containing filtered NDSI values\n",
    "        df_NDVI: dataframe containing filtered NDVI values\n",
    "        column: column name to aggregate, must contain 'Surf'\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"Surf\" not in column:\n",
    "        raise InputError(\"'Surf' must be found in column name, otherwise it is not an area column\")\n",
    "    \n",
    "    # Take sum of each day and average over the months to aggregate area data\n",
    "    daily_ndsi_surf_sum = df_NDSI.groupby(\n",
    "                            pd.PeriodIndex(df_NDSI.date, freq=\"D\")\n",
    "                        )[[column]].sum()\n",
    "    daily_ndvi_surf_sum = df_NDVI.groupby(\n",
    "                            pd.PeriodIndex(df_NDVI.date, freq=\"D\")\n",
    "                        )[[column]].sum()\n",
    "\n",
    "    monthly_ndsi_surf_mean = daily_ndsi_surf_sum.groupby(pd.PeriodIndex(\n",
    "                                daily_ndsi_surf_sum.index, freq=\"M\")\n",
    "                            )[[column]].mean()\n",
    "    monthly_ndvi_surf_mean = daily_ndvi_surf_sum.groupby(pd.PeriodIndex(\n",
    "                                daily_ndvi_surf_sum.index, freq=\"M\")\n",
    "                            )[[column]].mean()\n",
    "\n",
    "    surf_ndsi_mean_df = monthly_ndsi_surf_mean.reset_index()\n",
    "    surf_ndvi_mean_df = monthly_ndvi_surf_mean.reset_index()\n",
    "    surf_ndsi_mean_df = surf_ndsi_mean_df.rename({column: f\"ndsi_{column}\"},\n",
    "                                                 axis=\"columns\")\n",
    "    surf_ndvi_mean_df = surf_ndvi_mean_df.rename({column: f\"ndvi_{column}\"},\n",
    "                                                 axis=\"columns\")\n",
    "\n",
    "    surf_ndsi_ndvi_df = pd.merge(surf_ndsi_mean_df, surf_ndvi_mean_df)\n",
    "    \n",
    "    return surf_ndsi_ndvi_df\n",
    "\n",
    "def aggregate_ndsi_ndvi_data(df_NDSI, df_NDVI, area=False, cloud=False):\n",
    "    \"\"\"\n",
    "    Returns the aggregated NDSI NDVI data with lagged variables\n",
    "    Args:\n",
    "        df_NDSI: dataframe containing filtered NDSI values\n",
    "        df_NDVI: dataframe containing filtered NDVI values\n",
    "        area: denotes if we include the area as a feature\n",
    "        cloud: denotes if we include the cloud area as a feature\n",
    "    \"\"\"\n",
    "\n",
    "    # Take average of NDSI values for each month and aggregate\n",
    "    monthly_ndsi_mean = df_NDSI.groupby(pd.PeriodIndex(\n",
    "                            df_NDSI.date, freq=\"M\")\n",
    "                        )[[\"avg\"]].mean()\n",
    "    monthly_ndvi_mean = df_NDVI.groupby(pd.PeriodIndex(\n",
    "                            df_NDVI.date, freq=\"M\")\n",
    "                        )[[\"avg\"]].mean()\n",
    "\n",
    "    # Rename columns to enable merging\n",
    "    ndsi_mean_df = monthly_ndsi_mean.reset_index()\n",
    "    ndvi_mean_df = monthly_ndvi_mean.reset_index()\n",
    "\n",
    "    ndsi_mean_df = ndsi_mean_df.rename({\"avg\": \"ndsi_avg\"}, axis=\"columns\")\n",
    "    ndvi_mean_df = ndvi_mean_df.rename({\"avg\": \"ndvi_avg\"}, axis=\"columns\")\n",
    "\n",
    "    # Merge ndvi and ndsi dataframes into one\n",
    "    ndsi_ndvi_df = pd.merge(ndsi_mean_df, ndvi_mean_df)\n",
    "\n",
    "    if area:\n",
    "        surf_ndsi_ndvi_df = aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, \"Surfavg\")\n",
    "        ndsi_ndvi_df = pd.merge(ndsi_ndvi_df, surf_ndsi_ndvi_df)\n",
    "        \n",
    "    if cloud:\n",
    "        cloud_ndsi_ndvi_df = aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, \"Surfcloudavg\")\n",
    "        ndsi_ndvi_df = pd.merge(ndsi_ndvi_df, cloud_ndsi_ndvi_df)\n",
    "    \n",
    "    print(ndsi_ndvi_df.describe())\n",
    "    \n",
    "    return ndsi_ndvi_df\n",
    "\n",
    "\n",
    "def merge_flow_ndsi_ndvi_df(df_features, area=False, cloud=False):\n",
    "    \"\"\"\n",
    "    The ndsi_ndvi_mean_df will be merged into df_features and the\n",
    "    full dataframe is returned.\n",
    "    Args:\n",
    "        df_features: dataframe to merge ndsi_ndvi_df into\n",
    "    \"\"\"\n",
    "    watersheds = [\"03400\", \"03401\", \"03402\",\n",
    "                  \"03403\", \"03404\", \"03410\",\n",
    "                  \"03411\", \"03412\", \"03413\",\n",
    "                  \"03414\", \"03420\", \"03421\"]\n",
    "    df_ndsi, df_ndvi = gather_ndsi_ndvi_data(watersheds=watersheds)\n",
    "    df_ndsi_ndvi = aggregate_ndsi_ndvi_data(df_ndsi, df_ndvi, area=area, cloud=cloud)\n",
    "    \n",
    "    df_features = pd.merge(df_features, df_ndsi_ndvi, how=\"left\")\n",
    "    df_features = df_features.dropna(subset=[\"river_flow\"])\n",
    "    df_features = df_features.fillna(-1, downcast=\"infer\")\n",
    "\n",
    "    return df_features\n",
    "\n",
    "def gather_river_flow_data(lag=6, time_features=False, index_features=False, index_area_features=False, index_cloud_features=False):\n",
    "    \"\"\"\n",
    "    This function returns the full preprocessed data using various arguments\n",
    "    as a pd.DataFrame\n",
    "\n",
    "    Args:\n",
    "        int lag: amount of time lag to be used as features\n",
    "        bool time_features: use (cyclical) time as a feature\n",
    "    \"\"\"\n",
    "    processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "    # Import river flow data and only preserve datapoints after 1965\n",
    "    df_DGA = pd.read_csv(os.path.join(processed_folder_path, \"DGA.csv\"),\n",
    "                         index_col=0, parse_dates=[\"date\"])\n",
    "    df_DGA = df_DGA.loc[df_DGA[\"date\"].dt.year >= 1965]\n",
    "\n",
    "    # Extract average monthly river flow\n",
    "    monthly_flow_data_mean = df_DGA.groupby(\n",
    "                                    pd.PeriodIndex(df_DGA['date'], freq=\"M\")\n",
    "                                )['river_flow'].mean()\n",
    "    flow_mean_df = monthly_flow_data_mean.reset_index()\n",
    "    \n",
    "    print(flow_mean_df.describe())\n",
    "    \n",
    "    df_features = generate_lags(flow_mean_df, [\"river_flow\"], lag)\n",
    "\n",
    "    # Add time as feature if boolean is True\n",
    "    if time_features:\n",
    "\n",
    "        df_features = (\n",
    "            df_features\n",
    "            .assign(month=df_features.date.dt.month)\n",
    "        )\n",
    "\n",
    "        df_features = generate_cyclical_features(df_features, \"month\", 12, 1)\n",
    "\n",
    "    if index_features:\n",
    "        df_features = merge_flow_ndsi_ndvi_df(df_features, area=index_area_features, cloud=index_cloud_features)\n",
    "\n",
    "        # Convert dataset to lagged dataset\n",
    "        df_features = generate_lags(df_features, [\"ndsi_avg\", \"ndvi_avg\"], lag)\n",
    "        df_features = df_features.drop(columns=[\"ndsi_avg\", \"ndvi_avg\"])\n",
    "        \n",
    "        # Lag the ndsi and ndvi according to the same lag parameter and remove current month, \n",
    "        # as this cannot be used as a feature\n",
    "        if index_area_features:\n",
    "            df_features = generate_lags(df_features, [\"ndsi_Surfavg\", \"ndvi_Surfavg\"], lag)\n",
    "            df_features = df_features.drop(columns=[\"ndsi_Surfavg\", \"ndvi_Surfavg\"])\n",
    "        \n",
    "        if index_cloud_features:\n",
    "            df_features = generate_lags(df_features, [\"ndsi_Surfcloudavg\", \"ndvi_Surfcloudavg\"], lag)\n",
    "            df_features = df_features.drop(columns=[\"ndsi_Surfcloudavg\", \"ndvi_Surfcloudavg\"])\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643bd52",
   "metadata": {},
   "source": [
    "### Below we show a description of the aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b230b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = gather_river_flow_data(6, time_features=True, index_features=True, index_area_features=True, index_cloud_features=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
