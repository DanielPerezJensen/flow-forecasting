{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ed531f",
   "metadata": {},
   "source": [
    "### In this notebook we explore the data lightly and create some preliminary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc65a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "import collections\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import plotly.express as px\n",
    "\n",
    "processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "unprocessed_folder_path = os.path.join(\"..\", \"data\", \"unprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c137f9",
   "metadata": {},
   "source": [
    "## Plot data density\n",
    "\n",
    "### NDSI and NDVI data density given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDSI = pd.read_csv(os.path.join(processed_folder_path, \"NDSI.csv\"), index_col=0, parse_dates=[\"date\"],\n",
    "                     dtype={\"Subsubwatershed\": str})\n",
    "df_NDVI = pd.read_csv(os.path.join(processed_folder_path, \"NDVI.csv\"), index_col=0, parse_dates=[\"date\"],\n",
    "                     dtype={\"Subsubwatershed\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_density(dfs, labels):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for df, label in zip(dfs, labels):\n",
    "        plt.plot(df.groupby(df[\"date\"].dt.year).size(), label=label)\n",
    "    \n",
    "    plt.title(\"Frequency of years in data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for df, label in zip(dfs, labels):\n",
    "        plt.plot(df.groupby(df[\"date\"].dt.month).size(), label=label)\n",
    "\n",
    "    plt.xticks(range(12), range(1, 13))\n",
    "    plt.title(\"Frequency of months in data\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e31b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_density([df_NDSI, df_NDVI], [\"NDSI\", \"NDVI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02b8df",
   "metadata": {},
   "source": [
    "## River Flow Data\n",
    "### Data Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DGA = pd.read_csv(os.path.join(processed_folder_path, \"DGA.csv\"), index_col=0, parse_dates=[\"date\"])\n",
    "df_DGA = df_DGA.loc[df_DGA[\"date\"].dt.year >= 1965]\n",
    "\n",
    "plot_data_density([df_DGA], [\"DGA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1e6b8",
   "metadata": {},
   "source": [
    "### Monthly Flow Data\n",
    "\n",
    "We convert the data from a daily scale to a monthly scale by calculating the mean and the median per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22757983",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_flow_data_mean = df_DGA.groupby(pd.PeriodIndex(df_DGA['date'], freq=\"M\"))[['river_flow', 'river_height']].mean()\n",
    "monthly_flow_data_median = df_DGA.groupby(pd.PeriodIndex(df_DGA['date'], freq=\"M\"))['river_flow'].median()\n",
    "\n",
    "flow_mean_df = monthly_flow_data_mean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896018ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = [\"03400\", \"03401\", \"03402\", \n",
    "                \"03403\", \"03404\", \"03410\", \n",
    "                \"03411\", \"03412\", \"03413\", \n",
    "                \"03414\", \"03420\", \"03421\"]\n",
    "\n",
    "keep_rows_ndsi = df_NDSI[df_NDSI.Subsubwatershed.isin(station_list)].index\n",
    "keep_rows_ndvi = df_NDVI[df_NDVI.Subsubwatershed.isin(station_list)].index\n",
    "\n",
    "df_NDSI = df_NDSI[df_NDSI.index.isin(keep_rows_ndsi)]\n",
    "df_NDVI = df_NDVI[df_NDVI.index.isin(keep_rows_ndvi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_NDSI.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e5948",
   "metadata": {},
   "source": [
    "### Below we merge the NDSI and NDVI dataframes into the monthly_flow_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feed702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_ndsi_ndvi_data(watersheds=None):\n",
    "    \"\"\"\n",
    "    This function returns the full processed data using various arguments\n",
    "    as a pd.DataFrame\n",
    "    Args:\n",
    "        watersheds: list of strings denoting what watersheds to use from data\n",
    "        lag: amount of time lag to be used as features\n",
    "    \"\"\"\n",
    "    processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "    if watersheds == None:\n",
    "\n",
    "        watersheds = [\"03400\", \"03401\", \"03402\",\n",
    "                      \"03403\", \"03404\", \"03410\",\n",
    "                      \"03411\", \"03412\", \"03413\",\n",
    "                      \"03414\", \"03420\", \"03421\"]\n",
    "    \n",
    "    df_NDSI = pd.read_csv(os.path.join(processed_folder_path, \"NDSI.csv\"),\n",
    "                          index_col=0, parse_dates=[\"date\"],\n",
    "                          dtype={\"Subsubwatershed\": str})\n",
    "    df_NDVI = pd.read_csv(os.path.join(processed_folder_path, \"NDVI.csv\"),\n",
    "                          index_col=0, parse_dates=[\"date\"],\n",
    "                          dtype={\"Subsubwatershed\": str})\n",
    "    \n",
    "    # Only preserve rows inside subsubwatershed list\n",
    "    keep_rows_ndsi = df_NDSI[df_NDSI.Subsubwatershed.isin(watersheds)].index\n",
    "    keep_rows_ndvi = df_NDVI[df_NDVI.Subsubwatershed.isin(watersheds)].index\n",
    "\n",
    "    df_NDSI = df_NDSI[df_NDSI.index.isin(keep_rows_ndsi)]\n",
    "    df_NDVI = df_NDVI[df_NDVI.index.isin(keep_rows_ndvi)]\n",
    "    \n",
    "    return df_NDSI, df_NDVI\n",
    "\n",
    "\n",
    "def aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, column):\n",
    "    \"\"\"\n",
    "    This function will correctly aggregate area data given the column\n",
    "    Args:\n",
    "        df_NDSI: dataframe containing filtered NDSI values\n",
    "        df_NDVI: dataframe containing filtered NDVI values\n",
    "        column: column name to aggregate, must contain 'Surf'\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"Surf\" not in column:\n",
    "        raise InputError(\"'Surf' must be found in column name, otherwise it is not an area column\")\n",
    "    \n",
    "    # Take sum of each day and average over the months to aggregate area data\n",
    "    daily_ndsi_surf_sum = df_NDSI.groupby(\n",
    "                            pd.PeriodIndex(df_NDSI.date, freq=\"D\")\n",
    "                        )[[column]].sum()\n",
    "    daily_ndvi_surf_sum = df_NDVI.groupby(\n",
    "                            pd.PeriodIndex(df_NDVI.date, freq=\"D\")\n",
    "                        )[[column]].sum()\n",
    "\n",
    "    monthly_ndsi_surf_mean = daily_ndsi_surf_sum.groupby(pd.PeriodIndex(\n",
    "                                daily_ndsi_surf_sum.index, freq=\"M\")\n",
    "                            )[[column]].mean()\n",
    "    monthly_ndvi_surf_mean = daily_ndvi_surf_sum.groupby(pd.PeriodIndex(\n",
    "                                daily_ndvi_surf_sum.index, freq=\"M\")\n",
    "                            )[[column]].mean()\n",
    "\n",
    "    surf_ndsi_mean_df = monthly_ndsi_surf_mean.reset_index()\n",
    "    surf_ndvi_mean_df = monthly_ndvi_surf_mean.reset_index()\n",
    "    surf_ndsi_mean_df = surf_ndsi_mean_df.rename({column: f\"ndsi_{column}\"},\n",
    "                                                 axis=\"columns\")\n",
    "    surf_ndvi_mean_df = surf_ndvi_mean_df.rename({column: f\"ndvi_{column}\"},\n",
    "                                                 axis=\"columns\")\n",
    "\n",
    "    surf_ndsi_ndvi_df = pd.merge(surf_ndsi_mean_df, surf_ndvi_mean_df)\n",
    "    \n",
    "    return surf_ndsi_ndvi_df\n",
    "\n",
    "def aggregate_ndsi_ndvi_data(df_NDSI, df_NDVI, area=False, cloud=False):\n",
    "    \"\"\"\n",
    "    Returns the aggregated NDSI NDVI data with lagged variables\n",
    "    Args:\n",
    "        df_NDSI: dataframe containing filtered NDSI values\n",
    "        df_NDVI: dataframe containing filtered NDVI values\n",
    "        area: denotes if we include the area as a feature\n",
    "        cloud: denotes if we include the cloud area as a feature\n",
    "    \"\"\"\n",
    "\n",
    "    # Take average of NDSI values for each month and aggregate\n",
    "    monthly_ndsi_mean = df_NDSI.groupby(pd.PeriodIndex(\n",
    "                            df_NDSI.date, freq=\"M\")\n",
    "                        )[[\"avg\"]].mean()\n",
    "    monthly_ndvi_mean = df_NDVI.groupby(pd.PeriodIndex(\n",
    "                            df_NDVI.date, freq=\"M\")\n",
    "                        )[[\"avg\"]].mean()\n",
    "\n",
    "    # Rename columns to enable merging\n",
    "    ndsi_mean_df = monthly_ndsi_mean.reset_index()\n",
    "    ndvi_mean_df = monthly_ndvi_mean.reset_index()\n",
    "\n",
    "    ndsi_mean_df = ndsi_mean_df.rename({\"avg\": \"ndsi_avg\"}, axis=\"columns\")\n",
    "    ndvi_mean_df = ndvi_mean_df.rename({\"avg\": \"ndvi_avg\"}, axis=\"columns\")\n",
    "\n",
    "    # Merge ndvi and ndsi dataframes into one\n",
    "    ndsi_ndvi_df = pd.merge(ndsi_mean_df, ndvi_mean_df)\n",
    "\n",
    "    if area:\n",
    "        surf_ndsi_ndvi_df = aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, \"Surfavg\")\n",
    "        ndsi_ndvi_df = pd.merge(ndsi_ndvi_df, surf_ndsi_ndvi_df)\n",
    "        \n",
    "    if cloud:\n",
    "        cloud_ndsi_ndvi_df = aggregate_ndsi_ndvi_area_data(df_NDSI, df_NDVI, \"Surfcloudavg\")\n",
    "        ndsi_ndvi_df = pd.merge(ndsi_ndvi_df, cloud_ndsi_ndvi_df)\n",
    "    \n",
    "    return ndsi_ndvi_df\n",
    "\n",
    "def gather_data():\n",
    "    \"\"\"\n",
    "    This function returns the full preprocessed data using various arguments\n",
    "    as a pd.DataFrame\n",
    "    \"\"\"\n",
    "    processed_folder_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "    # Import river flow data and only preserve datapoints after 1965\n",
    "    df_DGA = pd.read_csv(os.path.join(processed_folder_path, \"DGA.csv\"),\n",
    "                         index_col=0, parse_dates=[\"date\"])\n",
    "    df_DGA = df_DGA.loc[df_DGA[\"date\"].dt.year >= 1965]\n",
    "\n",
    "    # Extract average monthly river flow\n",
    "    monthly_flow_data_mean = df_DGA.groupby(\n",
    "                                    pd.PeriodIndex(df_DGA['date'], freq=\"M\")\n",
    "                                )['river_flow'].mean()\n",
    "    flow_mean_df = monthly_flow_data_mean.reset_index()\n",
    "    \n",
    "    watersheds = [\"03400\", \"03401\", \"03402\",\n",
    "                  \"03403\", \"03404\", \"03410\",\n",
    "                  \"03411\", \"03412\", \"03413\",\n",
    "                  \"03414\", \"03420\", \"03421\"]\n",
    "    \n",
    "    ndsi_df, ndvi_df = gather_ndsi_ndvi_data(watersheds=watersheds)\n",
    "    ndsi_ndvi_df = aggregate_ndsi_ndvi_data(ndsi_df, ndvi_df, area=True, cloud=True)\n",
    "    \n",
    "    data_df = pd.merge(flow_mean_df, ndsi_ndvi_df, how=\"left\")\n",
    "    data_df = data_df.dropna(subset=[\"river_flow\"])\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643bd52",
   "metadata": {},
   "source": [
    "### Below we show a description of the aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b230b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = gather_data()\n",
    "data_df.date = data_df.date.dt.to_timestamp()\n",
    "data_df = data_df.set_index([\"date\"])\n",
    "print(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156901d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_col(df, col, title):\n",
    "    data = []\n",
    "    value = go.Scatter(\n",
    "        x = df.dropna(subset=[col]).index,\n",
    "        y = df.dropna(subset=[col])[col],\n",
    "        mode=\"lines\",\n",
    "        name=\"values\",\n",
    "        marker=dict(),\n",
    "        text=df.index,\n",
    "        line=dict(color=\"rgba(0.5,0,0, 0.3)\"),\n",
    "    )\n",
    "    \n",
    "    data.append(value)\n",
    "    \n",
    "    layout = dict(\n",
    "        title=title,\n",
    "        xaxis=dict(title=\"Date\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=col, ticklen=5, zeroline=False)\n",
    "    )\n",
    "    \n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6807016",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_df.columns:\n",
    "    plot_data_col(data_df, col, f\"Aggregated {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
